# Sistema de DetecciÃ³n de Somnolencia en Tiempo Real

Esta aplicaciÃ³n es una herramienta de seguridad desarrollada en Python que utiliza **VisiÃ³n por Computadora** e **Inteligencia Artificial** para monitorear el estado de alerta de un conductor o usuario en tiempo real.

Combina una interfaz grÃ¡fica moderna construida con **PyQt6** y un backend de procesamiento de imÃ¡genes que integra **OpenCV** (para detecciÃ³n facial y de ojos) y **TensorFlow/Keras** (para clasificaciÃ³n de bostezos mediante Deep Learning).

---

## ğŸ“‹ CaracterÃ­sticas Principales

âœ… **Interfaz GrÃ¡fica (GUI)**: Ventana amigable con visualizaciÃ³n de video en vivo e indicadores de estado codificados por colores.

âœ… **DetecciÃ³n de Rostro y Ojos**: Utiliza Haar Cascades para localizar el rostro y verificar si los ojos estÃ¡n abiertos o cerrados.

âœ… **DetecciÃ³n de Bostezos**: Emplea un modelo de red neuronal (CNN) cargado desde Keras para predecir si el usuario estÃ¡ bostezando.

âœ… **Alertas Visuales**:
- ğŸŸ¢ **Verde**: Estado normal/atento.
- ğŸŸ  **Naranja**: Bostezo detectado (Advertencia).
- ğŸ”´ **Rojo**: Ojos cerrados por tiempo prolongado (Alerta CrÃ­tica).

âœ… **Multihilo (Threading)**: El procesamiento de video se ejecuta en un hilo separado para no congelar la interfaz de usuario.

---

## ğŸ› ï¸ Requisitos del Sistema

Para ejecutar este proyecto, necesitas tener instalado **Python 3.8 o superior** y las siguientes librerÃ­as:

```bash
pip install opencv-python numpy PyQt6 tensorflow
```

**Dependencias principales:**
- `opencv-python` - VisiÃ³n por Computadora
- `numpy` - Operaciones con arrays
- `PyQt6` - Interfaz GrÃ¡fica
- `tensorflow` - Deep Learning

---

## ğŸ“‚ Estructura del Proyecto

Para que el cÃ³digo funcione correctamente, especialmente la funciÃ³n `resource_path`, se espera una estructura de directorios similar a la siguiente:

```
DetecionDeFatiga/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main.py            # El cÃ³digo principal de la aplicaciÃ³n
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ drowiness.keras    # Tu modelo entrenado (REQUERIDO)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

> **Nota:** El script busca automÃ¡ticamente los clasificadores Haar Cascade dentro de la instalaciÃ³n de `cv2`, pero el archivo `drowiness.keras` debe ser provisto por ti y colocado en la carpeta `assets`.

---

## ğŸ§  Arquitectura del CÃ³digo

El cÃ³digo estÃ¡ dividido en **tres componentes principales**:

### 1. `resource_path(relative_path)`

Una funciÃ³n utilitaria diseÃ±ada para manejar rutas de archivos de manera robusta. Permite que la aplicaciÃ³n funcione tanto en el entorno de desarrollo (ejecutando el script `.py`) como cuando se empaqueta en un ejecutable (usando PyInstaller), gestionando las rutas temporales de extracciÃ³n (`sys._MEIPASS`).

**Funcionamiento:**
```python
def resource_path(relative_path):
    try:
        # PyInstaller crea una carpeta temporal y almacena la ruta en _MEIPASS
        base_path = sys._MEIPASS
    except Exception:
        # En desarrollo, obtenemos el directorio del script actual (src/)
        # y subimos un nivel para acceder a la raÃ­z del proyecto
        base_path = Path(__file__).resolve().parent.parent
    
    return os.path.join(base_path, relative_path)
```

**Uso:**
```python
model_path = resource_path("assets/drowiness.keras")
```

---

### 2. Clase `VideoThread` (QThread)

Es el **nÃºcleo lÃ³gico** de la aplicaciÃ³n. Se ejecuta en segundo plano para capturar y procesar video.

#### ğŸ”§ Atributos Principales

| Atributo | Tipo | DescripciÃ³n |
|----------|------|-------------|
| `change_pixmap_signal` | `pyqtSignal(np.ndarray)` | SeÃ±al para enviar frames procesados a la UI |
| `status_signal` | `pyqtSignal(str, str)` | SeÃ±al para actualizar estado (texto, color) |
| `model` | `tf.keras.Model` | Modelo de red neuronal para clasificaciÃ³n |
| `face_cascade` | `cv2.CascadeClassifier` | Detector de rostros HaarCascade |
| `eye_cascade` | `cv2.CascadeClassifier` | Detector de ojos HaarCascade |
| `IMG_SIZE` | `145` | TamaÃ±o de entrada del modelo (145x145 pÃ­xeles) |
| `eyes_closed_frames` | `int` | Contador de frames consecutivos sin ojos detectados |
| `EYES_CLOSED_THRESHOLD` | `3` | Umbral de frames para alerta de ojos cerrados |

#### ğŸš€ InicializaciÃ³n: `load_resources()`

Carga el modelo `.keras` y los clasificadores XML (Haar Cascades).

**Recursos cargados:**
1. **Modelo de detecciÃ³n de bostezos**: `assets/drowiness.keras`
2. **HaarCascade para rostros**: `haarcascade_frontalface_default.xml`
3. **HaarCascade para ojos**: `haarcascade_eye.xml`

```python
# Cargar modelo Keras
model_path = resource_path("assets/drowiness.keras")
self.model = tf.keras.models.load_model(model_path)

# Cargar HaarCascades
face_cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
self.face_cascade = cv2.CascadeClassifier(face_cascade_path)

eye_cascade_path = cv2.data.haarcascades + 'haarcascade_eye.xml'
self.eye_cascade = cv2.CascadeClassifier(eye_cascade_path)
```

#### ğŸ”„ Ciclo `run()` - Loop Principal

1. **Captura un frame** de la cÃ¡mara web.
2. **Detecta el rostro** usando HaarCascade.
3. **LÃ³gica de Ojos**: Busca ojos dentro de la regiÃ³n del rostro. Si no detecta ojos durante `EYES_CLOSED_THRESHOLD` (3 frames consecutivos), activa la alerta de ojos cerrados.
4. **Preprocesamiento**: 
   - Recorta el rostro
   - Lo redimensiona a **145x145 pÃ­xeles**
   - Convierte de BGR a RGB
   - Normaliza los valores a rango [0, 1]
5. **Inferencia (TensorFlow)**: Pasa la imagen procesada al modelo para obtener la probabilidad de bostezo (`yawn` vs `no_yawn`).
6. **EmisiÃ³n de SeÃ±ales**: EnvÃ­a la imagen procesada y el estado (texto y color) a la interfaz grÃ¡fica.

**Diagrama del flujo:**

```
â”Œâ”€â†’ Capturar frame de cÃ¡mara
â”‚   â†“
â”‚   Convertir a escala de grises
â”‚   â†“
â”‚   Detectar rostros (HaarCascade)
â”‚   â†“
â”‚   â”Œâ”€ SI HAY ROSTRO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   â”‚                                     â”‚
â”‚   â”‚  Detectar ojos en regiÃ³n del rostro â”‚
â”‚   â”‚  â†“                                  â”‚
â”‚   â”‚  Actualizar contador ojos cerrados  â”‚
â”‚   â”‚  â†“                                  â”‚
â”‚   â”‚  Recortar y preparar ROI facial     â”‚
â”‚   â”‚  â†“                                  â”‚
â”‚   â”‚  Redimensionar a 145x145            â”‚
â”‚   â”‚  â†“                                  â”‚
â”‚   â”‚  Normalizar valores RGB [0,1]       â”‚
â”‚   â”‚  â†“                                  â”‚
â”‚   â”‚  Inferencia modelo TensorFlow       â”‚
â”‚   â”‚  â†“                                  â”‚
â”‚   â”‚  Interpretar predicciones:          â”‚
â”‚   â”‚  [prob_no_yawn, prob_yawn]          â”‚
â”‚   â”‚  â†“                                  â”‚
â”‚   â”‚  Determinar estado final:           â”‚
â”‚   â”‚  - Ojos cerrados â†’ ALERTA CRÃTICA   â”‚
â”‚   â”‚  - Bostezo â†’ ADVERTENCIA            â”‚
â”‚   â”‚  - Normal â†’ OK                      â”‚
â”‚   â”‚  â†“                                  â”‚
â”‚   â”‚  Emitir status_signal               â”‚
â”‚   â”‚  â†“                                  â”‚
â”‚   â”‚  Dibujar rectÃ¡ngulos y etiquetas    â”‚
â”‚   â”‚                                     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚   â†“
â”‚   NO HAY ROSTRO â†’ Emitir "Buscando rostro..."
â”‚   â†“
â”‚   Convertir BGR â†’ RGB para PyQt
â”‚   â†“
â”‚   Emitir change_pixmap_signal
â”‚   â†“
â””â”€ Loop (mientras _run_flag = True)
```

#### ğŸ¯ MÃ©todos Clave

##### `prepare_face(image_bgr, face_coords)`
Prepara una regiÃ³n facial para la inferencia del modelo.

**Proceso:**
1. Extrae ROI (Region of Interest) del rostro
2. Convierte de BGR a RGB
3. Redimensiona a 145x145 pÃ­xeles
4. Normaliza valores a rango [0, 1]
5. Reshape a formato del modelo: `(1, 145, 145, 3)`

##### `detect_eyes(face_gray, face_coords)`
Detecta la presencia de ojos en un rostro usando HaarCascade.

**ConfiguraciÃ³n:**
```python
eyes = self.eye_cascade.detectMultiScale(
    roi_gray,
    scaleFactor=1.1,
    minNeighbors=5,
    minSize=(20, 20)
)
return len(eyes) >= 1  # True si detecta al menos 1 ojo
```

##### `get_status_and_color(is_yawning, eyes_are_closed)`
Determina el estado del conductor y el color de alerta segÃºn prioridad:

1. ğŸ”´ **Alerta CrÃ­tica**: Ojos cerrados por 3+ frames
2. ğŸŸ  **Advertencia**: Bostezo detectado
3. ğŸŸ¢ **Normal**: Estado atento

**Retorno:** Tupla `(mensaje_estado, color_hex)`

---

### 3. Clase `DrowsinessDetectionApp` (QMainWindow)

Maneja la **presentaciÃ³n visual** y la **interacciÃ³n con el usuario**.

#### ğŸ–¼ï¸ Layout de la Interfaz

Utiliza un diseÃ±o vertical (`QVBoxLayout`) con los siguientes componentes:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸš— Sistema de DetecciÃ³n de Somnolencia      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                                        â”‚  â”‚
â”‚  â”‚     Video en Vivo (640x480)           â”‚  â”‚
â”‚  â”‚                                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Estado Actual:                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  âœ“ Estado Normal: Atento               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [â–¶ Iniciar DetecciÃ³n]  [â¹ Detener]         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ’¡ Consejo: MantÃ©n buena iluminaciÃ³n...    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ğŸ¨ Componentes de la UI

1. **TÃ­tulo**: Label con fuente Arial 20pt, negrita, color #2C3E50
2. **Frame de video**: QLabel con borde, fondo negro, tamaÃ±o mÃ­nimo 640x480
3. **Panel de estado**: Frame con fondo dinÃ¡mico segÃºn alertas
4. **Botones de control**:
   - **Iniciar**: Verde (#27AE60), habilitado por defecto
   - **Detener**: Rojo (#E74C3C), deshabilitado por defecto
5. **Consejo informativo**: Label en cursiva con color gris

#### ğŸ”Œ Slots (Conectores de SeÃ±ales)

##### `update_image(cv_img)`
Recibe el array numpy de la imagen desde `VideoThread`, lo convierte a `QPixmap` y lo muestra en el `QLabel`.

**Proceso:**
1. Extrae dimensiones (alto, ancho, canales)
2. Convierte a `QImage`
3. Escala manteniendo aspect ratio (`KeepAspectRatio`)
4. Actualiza el `QLabel` con el nuevo `QPixmap`

##### `update_status(status_text, color)`
Cambia dinÃ¡micamente el color y texto del panel de estado segÃºn las alertas recibidas del hilo de video.

**Estados posibles:**
- ğŸš¨ **ALERTA CRÃTICA: Ojos Cerrados** â†’ Rojo (#FF0000)
- âš ï¸ **ADVERTENCIA: Bostezo Detectado** â†’ Naranja (#FFA500)
- âœ“ **Estado Normal: Atento** â†’ Verde (#00FF00)
- âŒ› **Buscando rostro...** â†’ Amarillo

##### `start_detection()`
Inicia el proceso de detecciÃ³n:
1. Deshabilita botÃ³n "Iniciar"
2. Habilita botÃ³n "Detener"
3. Inicia el thread de video

##### `stop_detection()`
Detiene el proceso de detecciÃ³n:
1. Detiene el thread de video
2. Habilita botÃ³n "Iniciar"
3. Deshabilita botÃ³n "Detener"
4. Limpia el label de video
5. Resetea estado a "Sistema Detenido"

---

## ğŸš€ Uso

1. **AsegÃºrate de tener tu modelo entrenado** guardado como `assets/drowiness.keras`.

2. **Ejecuta el script principal**:
   ```bash
   python src/main.py
   ```

3. **Haz clic en el botÃ³n "â–¶ Iniciar DetecciÃ³n"**.

4. **Permite el acceso a la cÃ¡mara web**.

5. **Para detener el sistema**, presiona "â¹ Detener".

---

## âš™ï¸ ConfiguraciÃ³n de ParÃ¡metros

### DetecciÃ³n de Rostros

```python
faces = face_cascade.detectMultiScale(
    gray_frame, 
    scaleFactor=1.3,    # Mayor = mÃ¡s rÃ¡pido pero menos preciso
    minNeighbors=5,     # Mayor = menos falsos positivos
    minSize=(30, 30)    # TamaÃ±o mÃ­nimo del rostro en pÃ­xeles
)
```

### DetecciÃ³n de Ojos

```python
eyes = eye_cascade.detectMultiScale(
    roi_gray,
    scaleFactor=1.1,
    minNeighbors=5,
    minSize=(20, 20)
)
```

### Umbrales de Alerta

| ParÃ¡metro | Valor | DescripciÃ³n |
|-----------|-------|-------------|
| `EYES_CLOSED_THRESHOLD` | **3 frames** | Frames consecutivos sin ojos para alerta crÃ­tica |
| `IMG_SIZE` | **145 pÃ­xeles** | TamaÃ±o de entrada del modelo (145x145) |
| Umbral de bostezo | **Probabilidad relativa** | `prob_bostezo > prob_no_bostezo` |

---

## ğŸ” Formato de Salida del Modelo

El modelo de TensorFlow retorna un array con **2 probabilidades**:

```python
predictions = model.predict(prepared_face, verbose=0)
# Formato: [prob_no_bostezo, prob_bostezo]
# Ejemplo: [0.85, 0.15] â†’ 85% Normal, 15% Bostezo

yawn_prob = predictions[0][1]      # Probabilidad de bostezo
no_yawn_prob = predictions[0][0]   # Probabilidad de no bostezo

# ClasificaciÃ³n
is_yawning = yawn_prob > no_yawn_prob
```

---

## âš ï¸ SoluciÃ³n de Problemas Comunes

### âŒ Error "No se pudo abrir la cÃ¡mara"
**SoluciÃ³n**: Verifica que ninguna otra aplicaciÃ³n (Zoom, Teams, Skype) estÃ© usando la cÃ¡mara.

```bash
# En Linux, verifica dispositivos de video
ls /dev/video*
```

### âŒ Error al cargar `drowiness.keras`
**SoluciÃ³n**: AsegÃºrate de que la ruta del archivo sea correcta respecto a `src/main.py`. El cÃ³digo sube un nivel desde `src/` para buscar `assets/`.

```
âœ“ Correcto:
DetecionDeFatiga/
â”œâ”€â”€ src/main.py
â””â”€â”€ assets/drowiness.keras

âœ— Incorrecto:
DetecionDeFatiga/
â”œâ”€â”€ main.py  (deberÃ­a estar en src/)
â””â”€â”€ assets/drowiness.keras
```

### ğŸŒ Lentitud en la detecciÃ³n
**SoluciÃ³n**: TensorFlow puede ser pesado para CPU. 

**Opciones:**
- Si tienes una **GPU NVIDIA** configurada, TensorFlow la usarÃ¡ automÃ¡ticamente.
- Reduce la resoluciÃ³n de captura.
- Aumenta el intervalo de procesamiento.
- Considera usar TensorFlow Lite para dispositivos con recursos limitados.

### âŒ Error "HaarCascade not found"
**SoluciÃ³n**: Reinstala OpenCV con los datos incluidos:

```bash
pip uninstall opencv-python
pip install opencv-python opencv-contrib-python
```

---

## ğŸ¨ CaracterÃ­sticas de la Interfaz

### Estilos CSS/QSS Aplicados

**BotÃ³n Iniciar:**
```css
background-color: #27AE60 (Verde)
color: white
padding: 10px
border-radius: 5px
Hover: #229954
```

**BotÃ³n Detener:**
```css
background-color: #E74C3C (Rojo)
color: white
padding: 10px
border-radius: 5px
Hover: #C0392B
```

**Panel de Estado (DinÃ¡mico):**
- ğŸ”´ Alerta CrÃ­tica: `#FF0000`
- ğŸŸ  Advertencia: `#FFA500`
- ğŸŸ¢ Normal: `#00FF00`
- âšª Detenido: `#BDC3C7`

---

## ğŸš€ Optimizaciones Implementadas

1. âš¡ **Thread Separado**: Evita congelar la UI durante procesamiento intensivo
2. ğŸ”‡ **PredicciÃ³n Silenciosa**: `verbose=0` para no saturar logs
3. ğŸ“Š **DetecciÃ³n JerÃ¡rquica**: Primero rostro, luego ojos (mÃ¡s eficiente)
4. ğŸ¯ **NormalizaciÃ³n**: Valores [0, 1] mejoran rendimiento del modelo
5. ğŸ“ **Escalado Proporcional**: Mantiene calidad visual sin distorsiÃ³n

---

## ğŸ’¡ Posibles Mejoras Futuras

- ğŸ”Š **Alertas sonoras** cuando se detecte somnolencia crÃ­tica
- ğŸ“ **Registro de eventos** (logs con timestamps)
- âš™ï¸ **ConfiguraciÃ³n de umbrales** desde la UI
- ğŸ“¹ **Soporte multi-cÃ¡mara**
- ğŸ‘€ **DetecciÃ³n de distracciÃ³n** (mirada fuera de la carretera)
- ğŸ“„ **ExportaciÃ³n de reportes** en PDF/CSV
- ğŸ›ï¸ **CalibraciÃ³n personalizada** por usuario
- ğŸš— **IntegraciÃ³n con APIs** de telemetrÃ­a vehicular

---

## ğŸ“ CrÃ©ditos

Desarrollado utilizando:

- **PyQt6** - Interfaz GrÃ¡fica
- **OpenCV** - VisiÃ³n por Computadora
- **TensorFlow** - Deep Learning

---

**Autor**: Equipo de Desarrollo  
**Ãšltima actualizaciÃ³n**: Noviembre 2025  
**VersiÃ³n**: 1.0
